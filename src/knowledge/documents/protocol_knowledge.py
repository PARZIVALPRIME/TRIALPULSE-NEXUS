# File: src/knowledge/documents/protocol_knowledge.py
"""
Protocol Knowledge Base for Clinical Trials
Comprehensive knowledge about clinical trial protocols, procedures, and best practices.
"""

PROTOCOL_KNOWLEDGE_BASE = {
    "document_info": {
        "title": "Clinical Trial Protocol Knowledge Base",
        "version": "1.0.0",
        "last_updated": "2024-12-31",
        "purpose": "Provide comprehensive protocol knowledge for clinical trial operations"
    },
    
    "sections": [
        # Section 1: Data Quality Management
        {
            "section_id": "DQ-001",
            "category": "data_quality",
            "title": "Data Quality Index (DQI) Management",
            "content": """
DATA QUALITY INDEX (DQI) OVERVIEW

The Data Quality Index (DQI) is a composite score measuring overall data quality for clinical trial subjects. It ranges from 0-100, with higher scores indicating better data quality.

DQI COMPONENTS AND WEIGHTS:
1. Safety Score (25%): Measures SAE reconciliation and safety data completeness
   - SAE-DM discrepancies between data management and safety teams
   - SAE-Safety pending items requiring physician review
   - Critical for patient safety and regulatory compliance

2. Query Score (20%): Measures query management efficiency
   - Open queries requiring resolution
   - Query aging (older queries penalized more heavily)
   - Query types: DM queries, clinical queries, medical queries, site queries

3. Completeness Score (15%): Measures data collection completeness
   - Missing visits that should have been completed
   - Missing CRF pages within visits
   - Days outstanding for missing data

4. Coding Score (12%): Measures medical/drug coding status
   - MedDRA coding for adverse events and medical history
   - WHODrug coding for concomitant medications
   - Uncoded terms block database lock

5. Lab Score (10%): Measures laboratory data quality
   - Missing lab values
   - Out-of-range values requiring confirmation
   - Lab name/range issues

6. SDV Score (8%): Measures source data verification progress
   - CRFs requiring SDV that have been verified
   - SDV completion rate per subject

7. Signature Score (5%): Measures electronic signature compliance
   - CRFs requiring signatures that are signed
   - Overdue signatures (within 45 days, beyond 90 days)
   - Broken signatures requiring re-signing

8. EDRR Score (5%): Measures external data reconciliation
   - Third-party data reconciliation issues
   - ECG, imaging, central lab discrepancies

DQI MULTIPLIERS:
- Age Multiplier: Issues older than 30 days receive 1.6x penalty
- Criticality Multiplier: Safety issues receive 1.5x penalty
- Trend Multiplier: Worsening trends receive 1.25x penalty

DQI BANDS:
- Pristine (95-100): Exceptional quality, ready for lock
- Excellent (85-95): Minor issues only
- Good (75-85): Some attention needed
- Fair (65-75): Significant issues present
- Poor (50-65): Major intervention required
- Critical (25-50): Immediate action needed
- Emergency (<25): Trial integrity at risk

BEST PRACTICES:
1. Monitor DQI weekly at minimum
2. Focus on high-weight components first (Safety, Query)
3. Address aging issues before they accumulate penalties
4. Use cascade analysis to find root causes
5. Track trends to predict future issues
            """,
            "keywords": ["DQI", "data quality", "score", "metrics", "components", "weights"],
            "related_sections": ["DQ-002", "DQ-003", "CL-001"]
        },
        
        {
            "section_id": "DQ-002",
            "category": "data_quality",
            "title": "Query Management Best Practices",
            "content": """
QUERY MANAGEMENT IN CLINICAL TRIALS

Queries are formal requests for clarification or correction of clinical trial data. Effective query management is critical for data quality and timely database lock.

QUERY TYPES:
1. DM Queries: Generated by data management for data discrepancies
2. Clinical Queries: Medical/clinical questions about subject data
3. Medical Queries: Require medical monitor review
4. Site Queries: Administrative or procedural questions
5. Coding Queries: Questions about adverse event or medication coding
6. Safety Queries: Related to safety reporting discrepancies

QUERY LIFECYCLE:
1. Generation: Query created (auto or manual)
2. Open: Query sent to site for response
3. Answered: Site provides response
4. Closed: Response accepted, query resolved
5. Re-opened: Response insufficient, additional clarification needed

QUERY AGING CATEGORIES:
- Fresh (0-7 days): Normal processing time
- Aging (8-14 days): Requires attention
- Overdue (15-30 days): Escalation needed
- Critical (>30 days): Immediate intervention required

QUERY RESOLUTION STRATEGIES:
1. Batch Processing: Group similar queries for efficient resolution
2. Priority Triage: Address safety and critical queries first
3. Root Cause Analysis: Identify patterns to prevent future queries
4. Site Training: Reduce query volume through education
5. Template Responses: Standardize common query responses

QUERY METRICS TO TRACK:
- Query rate per subject
- Query aging distribution
- Query resolution time
- Query re-open rate
- Queries by type and site

ESCALATION PROCEDURES:
- Day 7: First reminder to site
- Day 14: CRA follow-up
- Day 21: Site management notification
- Day 30: Study lead escalation
- Day 45+: Sponsor notification

BEST PRACTICES:
1. Respond to queries within 5 business days
2. Provide complete answers to avoid re-opening
3. Include source documentation when available
4. Address root cause, not just symptoms
5. Use cascade analysis to prioritize
            """,
            "keywords": ["query", "queries", "resolution", "aging", "escalation", "data clarification"],
            "related_sections": ["DQ-001", "CL-002", "SI-001"]
        },
        
        {
            "section_id": "DQ-003",
            "category": "data_quality",
            "title": "Source Data Verification (SDV) Procedures",
            "content": """
SOURCE DATA VERIFICATION (SDV) PROCEDURES

SDV is the process of comparing data entered in CRFs against source documents to ensure accuracy and completeness.

SDV REQUIREMENTS:
1. 100% SDV: All data points verified against source
2. Risk-Based SDV: Targeted verification based on risk assessment
3. Reduced SDV: Verification of critical data points only

SDV-REQUIRED DATA TYPICALLY INCLUDES:
- Informed consent date and signature
- Eligibility criteria
- Primary endpoint data
- Serious adverse events
- Protocol deviations
- Study drug administration
- Key safety assessments

SDV PROCESS:
1. CRA accesses source documents at site
2. Compares each data point to CRF entry
3. Documents any discrepancies found
4. Generates queries for corrections
5. Records SDV completion in monitoring report

SDV DOCUMENTATION:
- Date of verification
- CRA performing SDV
- Source document reviewed
- Discrepancies identified
- Resolution status

REMOTE SDV CONSIDERATIONS:
- Certified copies of source documents
- Secure transfer methods
- Privacy/confidentiality requirements
- Regulatory authority acceptance

SDV COMPLETION TARGETS:
- Pre-lock: 100% of required SDV complete
- Interim: Per monitoring plan schedule
- Risk-based: Critical data 100%, other per plan

COMMON SDV FINDINGS:
1. Transcription errors
2. Missing data
3. Date inconsistencies
4. Unit conversion errors
5. Incomplete documentation

SDV BEST PRACTICES:
1. Complete SDV during each monitoring visit
2. Prioritize safety and efficacy data
3. Document all findings thoroughly
4. Follow up on outstanding issues
5. Update monitoring reports promptly
            """,
            "keywords": ["SDV", "source data verification", "monitoring", "CRA", "source documents"],
            "related_sections": ["DQ-001", "MO-001", "SI-002"]
        },
        
        # Section 2: Clean Patient Criteria
        {
            "section_id": "CL-001",
            "category": "clean_patient",
            "title": "Two-Tier Clean Patient Definition",
            "content": """
TWO-TIER CLEAN PATIENT DEFINITION

Clean Patient status indicates a subject's data is ready for database lock. TRIALPULSE uses a two-tier system.

TIER 1: CLINICAL CLEAN (Hard Blocks)
These criteria MUST be met for clinical data integrity:

1. No Missing Visits (visit_missing_visit_count = 0)
   - All protocol-required visits completed
   - Visit data entered in EDC

2. No Missing Pages (pages_missing_page_count = 0)
   - All required CRF pages completed
   - No blank or partially completed forms

3. No Open Queries (total_open_queries = 0)
   - All queries resolved and closed
   - No pending clarifications

4. SDV Complete (crfs_source_data_verified = crfs_requiring_sdv)
   - All required SDV performed
   - 100% verification rate

5. Signatures Complete (crfs_signed >= crfs_requiring_signature)
   - All required signatures obtained
   - No pending PI signatures

6. MedDRA Coding Complete (meddra_coded_terms = meddra_total_terms)
   - All adverse events coded
   - No pending medical coding

7. WHODrug Coding Complete (whodrug_coded_terms = whodrug_total_terms)
   - All medications coded
   - No pending drug coding

TIER 2: OPERATIONAL CLEAN (Soft Blocks)
Additional criteria for operational readiness:

1. No Lab Issues (lab_issue_count = 0)
   - No missing lab values
   - No unconfirmed out-of-range values

2. No SAE-DM Pending (sae_dm_pending = 0)
   - All SAE data reconciled
   - DM and Safety aligned

3. No SAE-Safety Pending (sae_safety_pending = 0)
   - All safety reviews complete
   - No pending physician review

4. No EDRR Issues (edrr_issue_count = 0)
   - External data reconciled
   - No third-party discrepancies

5. No Overdue Signatures (crfs_overdue_for_signs = 0)
   - No aging signature issues
   - All signatures current

6. No Broken Signatures (broken_signatures = 0)
   - No invalidated signatures
   - All e-signatures valid

7. No Inactivated Forms (inactivated_total = 0)
   - No deactivated pages requiring review
   - All form status resolved

CLEAN PATIENT CATEGORIES:
- Tier 2 Clean: Meets all 14 criteria (both tiers)
- Tier 1 Clean: Meets 7 hard block criteria only
- Not Clean: One or more hard blocks present

EFFORT ESTIMATION:
Each blocking criterion has estimated resolution time:
- Missing Visit: 2 hours (site)
- Missing Page: 1.5 hours (site)
- Open Query: 0.5 hours (site/DM)
- SDV: 0.25 hours per CRF (CRA)
- Signature: 0.1 hours per form (site)
- Coding: 0.15 hours per term (coder)

QUICK WINS:
Patients with 1-2 issues blocking Tier 1 status are "quick wins" that can rapidly improve clean rates with minimal effort.
            """,
            "keywords": ["clean patient", "tier 1", "tier 2", "hard blocks", "soft blocks", "database lock"],
            "related_sections": ["DQ-001", "CL-002", "DB-001"]
        },
        
        {
            "section_id": "CL-002",
            "category": "clean_patient",
            "title": "Blocking Reason Resolution Guide",
            "content": """
BLOCKING REASON RESOLUTION GUIDE

This guide provides resolution strategies for each blocking criterion.

1. MISSING VISITS
Root Causes:
- Subject missed scheduled visit
- Visit not entered in EDC
- Visit scheduled but not completed

Resolution Steps:
a. Check if visit was completed but not entered
b. Verify if visit was rescheduled
c. If visit missed, document reason
d. If visit cannot be recovered, document as protocol deviation
e. Update visit status in EDC

Responsible: Site Coordinator, CRA

2. MISSING PAGES
Root Causes:
- Form not completed during visit
- Data entry incomplete
- Form inadvertently skipped

Resolution Steps:
a. Review source documents for data
b. Complete missing CRF pages
c. If data unavailable, query site
d. Document reason for missing data
e. Obtain required signatures

Responsible: Site Coordinator, Data Manager

3. OPEN QUERIES
Root Causes:
- Data discrepancy identified
- Clarification needed
- Incomplete data entry

Resolution Steps:
a. Review query details
b. Check source documents
c. Provide complete response
d. Make CRF corrections if needed
e. Verify query closure

Responsible: Site (response), Data Manager (review)

4. SDV INCOMPLETE
Root Causes:
- Monitoring visit not scheduled
- Source documents not available
- CRA access issues

Resolution Steps:
a. Schedule monitoring visit
b. Prepare source documents
c. Complete SDV during visit
d. Document in monitoring report
e. Close any discrepancies found

Responsible: CRA, Site Coordinator

5. SIGNATURES PENDING
Root Causes:
- PI/Sub-I not available
- Signature workflow not initiated
- Technical issues with e-signature

Resolution Steps:
a. Notify PI of pending signatures
b. Schedule signature session
c. Complete batch signatures
d. Verify signature completion
e. Re-sign any broken signatures

Responsible: Site (PI/Sub-I)

6. CODING INCOMPLETE
Root Causes:
- New terms requiring coding
- Ambiguous verbatim terms
- Coding backlog

Resolution Steps:
a. Review uncoded terms
b. Apply standard coding
c. Escalate ambiguous terms
d. Request site clarification if needed
e. Document coding decisions

Responsible: Medical Coder

7. SAE RECONCILIATION
Root Causes:
- Data entry timing differences
- Missing SAE forms
- Discrepant information

Resolution Steps:
a. Compare DM and Safety records
b. Identify discrepancies
c. Request missing forms
d. Reconcile conflicting data
e. Confirm alignment

Responsible: Safety Data Manager
            """,
            "keywords": ["blocking reason", "resolution", "missing visits", "queries", "SDV", "signatures", "coding"],
            "related_sections": ["CL-001", "DQ-002", "DQ-003"]
        },
        
        # Section 3: Database Lock
        {
            "section_id": "DB-001",
            "category": "database_lock",
            "title": "Database Lock Readiness Assessment",
            "content": """
DATABASE LOCK READINESS ASSESSMENT

Database lock is the point at which clinical trial data is frozen for statistical analysis. Proper preparation is critical for data integrity and regulatory compliance.

DB LOCK ELIGIBILITY:
Subjects eligible for DB Lock assessment:
- Completed: Finished all protocol visits
- Discontinued: Early termination with data complete
- Ongoing: May be locked if all available data clean

Subjects NOT eligible:
- Screen Failures: Excluded from efficacy analysis
- Screening: Still in screening process
- Unknown Status: Status needs clarification

DB LOCK READINESS TIERS:

TIER 1: FULLY READY
- All Tier 1 Clean criteria met
- All Tier 2 Clean criteria met
- No pending issues of any kind
- Can be locked immediately

TIER 2: PENDING
- Tier 1 Clean (hard blocks resolved)
- Some Tier 2 issues remain
- Can be frozen pending final cleanup
- 1-7 days to full readiness

TIER 3: BLOCKED
- One or more hard blocks present
- Cannot proceed to lock
- Requires active intervention
- Timeline depends on issue severity

DB LOCK PROCESS:
1. Pre-Lock Activities:
   - Complete all data entry
   - Resolve all queries
   - Complete SDV and signatures
   - Reconcile external data
   - Freeze subject data

2. Data Review:
   - Medical review of key data
   - Safety review complete
   - Protocol deviation review
   - Eligibility confirmation

3. Lock Execution:
   - Lock subjects in batches
   - Document lock status
   - Archive essential documents
   - Notify stakeholders

4. Post-Lock Activities:
   - Statistical analysis
   - Data export
   - Archive procedures
   - Unlock procedures (if needed)

DB LOCK METRICS:
- % Ready: Subjects meeting all criteria
- Days to Ready: Average time to resolve issues
- Blocking Reasons: Distribution of issues
- Trend: Improvement over time

CRITICAL PATH TO LOCK:
Use cascade analysis to identify:
1. Issues blocking most subjects
2. Dependencies between issues
3. Optimal resolution sequence
4. Resource requirements

DB LOCK TIMELINE:
- 4 weeks before: 80% Tier 2 clean target
- 2 weeks before: 95% Tier 1 clean target
- 1 week before: All subjects frozen
- Lock day: Final lock execution
            """,
            "keywords": ["database lock", "DB lock", "readiness", "freeze", "data integrity"],
            "related_sections": ["CL-001", "CL-002", "DB-002"]
        },
        
        {
            "section_id": "DB-002",
            "category": "database_lock",
            "title": "Database Lock Checklist",
            "content": """
DATABASE LOCK CHECKLIST

Pre-Lock Verification Checklist:

DATA ENTRY COMPLETE:
☐ All CRF pages entered
☐ All visits completed or documented
☐ All protocol deviations recorded
☐ All AEs/SAEs entered and coded
☐ All concomitant medications entered

QUERIES RESOLVED:
☐ All queries closed
☐ No pending query responses
☐ Query resolution documented
☐ Final query review complete

SDV COMPLETE:
☐ 100% SDV for required fields
☐ SDV documented in monitoring reports
☐ All discrepancies resolved
☐ Final monitoring visit complete

SIGNATURES OBTAINED:
☐ All PI signatures complete
☐ All required e-signatures valid
☐ No broken signatures
☐ Signature log current

CODING COMPLETE:
☐ All AEs coded (MedDRA)
☐ All medications coded (WHODrug)
☐ Coding review complete
☐ Coding dictionaries locked

SAFETY DATA:
☐ SAE reconciliation complete
☐ DM-Safety alignment verified
☐ All safety reviews finalized
☐ Safety database locked

EXTERNAL DATA:
☐ Lab data reconciled
☐ ECG data reconciled
☐ Central imaging reviewed
☐ EDRR issues resolved

REGULATORY:
☐ Protocol deviations assessed
☐ Eligibility confirmed
☐ Essential documents complete
☐ Audit trail verified

SYSTEM CHECKS:
☐ Edit checks passed
☐ Validation rules satisfied
☐ Data export tested
☐ Archive procedures ready

APPROVALS:
☐ Data management approval
☐ Medical monitor approval
☐ Study lead approval
☐ Sponsor approval

POST-LOCK PROCEDURES:
☐ Unblinding plan ready
☐ Analysis datasets defined
☐ Statistical analysis plan final
☐ Archive procedures documented
            """,
            "keywords": ["checklist", "database lock", "verification", "approval", "pre-lock"],
            "related_sections": ["DB-001", "CL-001", "SA-001"]
        },
        
        # Section 4: Safety Reporting
        {
            "section_id": "SA-001",
            "category": "safety",
            "title": "SAE Reporting and Reconciliation",
            "content": """
SERIOUS ADVERSE EVENT (SAE) REPORTING AND RECONCILIATION

SAE DEFINITION (ICH E2A):
A Serious Adverse Event is any untoward medical occurrence that:
- Results in death
- Is life-threatening
- Requires inpatient hospitalization or prolongation of existing hospitalization
- Results in persistent or significant disability/incapacity
- Is a congenital anomaly/birth defect
- Is an important medical event

SAE REPORTING TIMELINE:
- Fatal/Life-threatening: Within 24 hours of awareness
- Other SAEs: Within 24-72 hours per protocol
- Follow-up reports: Within 24 hours of new information

SAE REPORTING WORKFLOW:
1. Site identifies SAE
2. Complete initial SAE form
3. Submit to sponsor/safety team
4. Enter in EDC (Data Management)
5. Safety team reviews
6. Regulatory reporting if required
7. Follow-up until resolution

SAE RECONCILIATION:
Purpose: Ensure alignment between:
- Data Management (EDC entries)
- Safety Database (safety system entries)
- Regulatory submissions

Reconciliation Process:
1. Compare SAE listings from both systems
2. Identify discrepancies:
   - Missing SAEs (in one system only)
   - Date discrepancies
   - Outcome discrepancies
   - Causality discrepancies
3. Investigate root cause
4. Correct errors in appropriate system
5. Document reconciliation
6. Confirm alignment

SAE METRICS:
- SAE-DM pending: SAEs awaiting DM completion
- SAE-Safety pending: SAEs awaiting safety review
- Reconciliation rate: % aligned between systems
- Reporting compliance: % within timeline

ESCALATION FOR SAE ISSUES:
- 24 hours: First notification
- 48 hours: CRA/Safety team follow-up
- 72 hours: Study lead notification
- 7 days: Sponsor escalation

SAE DOCUMENTATION REQUIREMENTS:
- Event description
- Onset and resolution dates
- Severity and seriousness criteria
- Relationship to study drug
- Action taken with study drug
- Outcome
- Reporter information
            """,
            "keywords": ["SAE", "serious adverse event", "safety reporting", "reconciliation", "pharmacovigilance"],
            "related_sections": ["SA-002", "DQ-001", "CL-001"]
        },
        
        {
            "section_id": "SA-002",
            "category": "safety",
            "title": "Safety Signal Detection",
            "content": """
SAFETY SIGNAL DETECTION IN CLINICAL TRIALS

SIGNAL DEFINITION:
A safety signal is information about a new or known adverse event that warrants further investigation.

SIGNAL SOURCES:
1. Individual case reports (SAEs/AEs)
2. Aggregate safety data analysis
3. Literature reports
4. Regulatory authority notifications
5. Post-marketing reports

SIGNAL DETECTION METHODS:

Quantitative Methods:
- Proportional Reporting Ratio (PRR)
- Reporting Odds Ratio (ROR)
- Bayesian methods (BCPNN, MGPS)
- Time-to-onset analysis

Qualitative Methods:
- Clinical review of individual cases
- Pattern recognition
- Expert assessment
- Literature review

SIGNAL CRITERIA:
Statistical threshold: Typically >2σ above baseline
Considerations:
- Number of cases
- Biological plausibility
- Temporal relationship
- Dose-response relationship
- Consistency across studies

SIGNAL RESPONSE:
1. Detection: Identify potential signal
2. Validation: Confirm signal is real
3. Analysis: Characterize signal
4. Assessment: Evaluate clinical significance
5. Action: Determine response
6. Communication: Notify stakeholders
7. Monitoring: Continue surveillance

TRIALPULSE PATTERN DETECTION:
The system monitors for:
- Cluster patterns (same AE at multiple sites)
- Temporal patterns (AE onset timing)
- Demographic patterns (specific populations)
- Geographic patterns (regional differences)

Alert triggers when:
- AE rate > 2σ above baseline
- Cluster of similar AEs detected
- Unexpected AE pattern identified

DOCUMENTATION:
All signal detection activities should be documented:
- Date of detection
- Signal description
- Analysis performed
- Conclusions
- Actions taken
            """,
            "keywords": ["safety signal", "detection", "pharmacovigilance", "adverse events", "patterns"],
            "related_sections": ["SA-001", "AN-001", "PA-001"]
        },
        
        # Section 5: Monitoring
        {
            "section_id": "MO-001",
            "category": "monitoring",
            "title": "Risk-Based Monitoring Approach",
            "content": """
RISK-BASED MONITORING (RBM) APPROACH

RBM DEFINITION:
Risk-Based Monitoring is an adaptive approach that directs monitoring activities based on risk assessment, focusing resources on critical data and processes.

ICH E6(R2) REQUIREMENTS:
- Quality management approach
- Risk-proportionate monitoring
- Centralized monitoring as primary method
- On-site monitoring as supplement

RISK ASSESSMENT COMPONENTS:

1. Risk Identification:
- Subject safety risks
- Data integrity risks
- Protocol compliance risks
- Operational risks

2. Risk Evaluation:
- Likelihood of occurrence
- Impact if occurs
- Detectability
- Risk priority number (RPN)

3. Risk Control:
- Prevention measures
- Detection measures
- Mitigation actions

MONITORING MODALITIES:

Centralized Monitoring:
- Remote data review
- Statistical analyses
- Key Risk Indicators (KRIs)
- Cross-site comparisons
- Trend analysis

On-Site Monitoring:
- SDV of critical data
- Source document review
- Site staff interviews
- Facility inspection
- Protocol compliance verification

KEY RISK INDICATORS (KRIs):
- Enrollment rate
- Screen failure rate
- Protocol deviation rate
- Query rate
- SAE rate
- Data entry timeliness
- Missing data rate

MONITORING PLAN ELEMENTS:
1. Risk assessment summary
2. Monitoring strategy (central vs. on-site)
3. Visit frequency and triggers
4. SDV strategy
5. Essential data verification
6. Escalation procedures
7. Documentation requirements

SITE PERFORMANCE TIERS:
- Green: Low risk, routine monitoring
- Yellow: Moderate risk, enhanced monitoring
- Red: High risk, intensive monitoring
            """,
            "keywords": ["monitoring", "risk-based", "RBM", "KRI", "centralized monitoring", "on-site"],
            "related_sections": ["MO-002", "DQ-003", "SI-001"]
        },
        
        {
            "section_id": "MO-002",
            "category": "monitoring",
            "title": "Monitoring Visit Report Requirements",
            "content": """
MONITORING VISIT REPORT REQUIREMENTS

PURPOSE:
The monitoring visit report documents findings from each site visit, ensuring proper trial conduct and regulatory compliance.

REPORT TIMING:
- Submit within 10 business days of visit
- Critical findings reported immediately
- Follow-up items tracked to resolution

REPORT SECTIONS:

1. ADMINISTRATIVE INFORMATION:
- Visit date and type
- Site identification
- Monitor name and signature
- Persons met
- Previous visit date

2. SUBJECT STATUS:
- Enrolled subjects
- Screen failures
- Discontinuations
- Completed subjects
- Active subjects

3. INFORMED CONSENT REVIEW:
- Consents reviewed
- Issues identified
- Re-consent requirements

4. SOURCE DATA VERIFICATION:
- Subjects reviewed
- Data points verified
- Discrepancies found
- Corrections made

5. INVESTIGATIONAL PRODUCT:
- Accountability review
- Storage conditions
- Expiry dates
- Dispensing records

6. ESSENTIAL DOCUMENTS:
- Documents reviewed
- Updates needed
- Filing compliance

7. PROTOCOL DEVIATIONS:
- New deviations identified
- Previous deviations status
- Corrective actions

8. SAFETY REVIEW:
- SAE review
- AE documentation
- Reporting compliance

9. QUERY STATUS:
- Open queries reviewed
- Aging queries addressed
- Resolution tracking

10. ACTION ITEMS:
- Items from current visit
- Items from previous visits
- Responsible parties
- Due dates

REPORT DISTRIBUTION:
- Sponsor
- CRO (if applicable)
- Site file (if required)
- Regulatory file

REPORT ARCHIVING:
- Part of Trial Master File
- Retained per retention requirements
- Available for audit/inspection
            """,
            "keywords": ["monitoring report", "visit report", "documentation", "CRA", "findings"],
            "related_sections": ["MO-001", "ES-001", "DQ-003"]
        },
        
        # Section 6: Site Management
        {
            "section_id": "SI-001",
            "category": "site_management",
            "title": "Site Performance Assessment",
            "content": """
SITE PERFORMANCE ASSESSMENT

PURPOSE:
Systematic evaluation of site performance to identify issues early and ensure trial success.

PERFORMANCE METRICS:

Enrollment Metrics:
- Enrollment rate (subjects/month)
- Screen failure rate
- Randomization rate
- Time to first enrollment

Data Quality Metrics:
- DQI score (composite)
- Query rate per subject
- Query aging
- Missing data rate

Compliance Metrics:
- Protocol deviation rate
- SAE reporting compliance
- Visit window compliance
- Document submission timeliness

Operational Metrics:
- CRF completion time
- Query response time
- Signature turnaround
- Staff turnover

PERFORMANCE TIERS:

Exceptional (Top 10%):
- Benchmark site
- Potential for increased enrollment
- Reduced monitoring frequency

Strong (70-90th percentile):
- Meeting expectations
- Standard monitoring
- Minor improvement opportunities

Average (30-70th percentile):
- Acceptable performance
- Some attention needed
- Standard monitoring

Below Average (10-30th percentile):
- Needs improvement
- Enhanced monitoring
- Action plan required

Needs Improvement (Bottom 10%):
- Significant concerns
- Intensive monitoring
- Remediation required
- Potential for closure

PERFORMANCE IMPROVEMENT PROCESS:
1. Identify performance gaps
2. Root cause analysis
3. Develop action plan
4. Implement corrections
5. Monitor progress
6. Document outcomes

SITE BENCHMARKING:
Compare sites within:
- Same region
- Same study
- Similar size
- Similar start date

ESCALATION TRIGGERS:
- DQI < 70 for 2 consecutive months
- Query rate > 2x study average
- > 5 major protocol deviations
- SAE reporting non-compliance
            """,
            "keywords": ["site performance", "metrics", "assessment", "benchmarking", "improvement"],
            "related_sections": ["SI-002", "MO-001", "DQ-001"]
        },
        
        {
            "section_id": "SI-002",
            "category": "site_management",
            "title": "Site Issue Escalation Procedures",
            "content": """
SITE ISSUE ESCALATION PROCEDURES

ESCALATION LEVELS:

LEVEL 1: CRA MANAGEMENT (Days 1-7)
Triggers:
- Minor data quality issues
- Routine query aging
- Minor compliance gaps

Actions:
- Document in visit report
- Discuss with site coordinator
- Provide training if needed
- Set resolution timeline

LEVEL 2: CTM INVOLVEMENT (Days 8-14)
Triggers:
- Persistent Level 1 issues
- Moderate protocol deviations
- Pattern of non-compliance

Actions:
- CTM notified
- Formal communication to site
- Action plan development
- Enhanced monitoring scheduled

LEVEL 3: STUDY LEAD ESCALATION (Days 15-21)
Triggers:
- Unresolved Level 2 issues
- Major protocol deviations
- Safety concerns
- Significant data quality issues

Actions:
- Study lead notification
- Call with PI/site leadership
- Written improvement plan
- Timeline for resolution

LEVEL 4: SPONSOR NOTIFICATION (Days 22-30)
Triggers:
- Critical safety issues
- Persistent non-compliance
- Data integrity concerns
- Regulatory risk

Actions:
- Sponsor immediately notified
- Formal warning letter
- Remediation plan required
- Consideration for site closure

LEVEL 5: SITE CLOSURE CONSIDERATION (Day 30+)
Triggers:
- Failed remediation
- Continued non-compliance
- Subject safety at risk
- Fraudulent behavior

Actions:
- Site closure evaluation
- Subject transfer planning
- Regulatory notifications
- Documentation complete

DOCUMENTATION REQUIREMENTS:
Each escalation level must document:
- Issue description
- Timeline of events
- Actions taken
- Site response
- Resolution status
- Next steps

COMMUNICATION TEMPLATES:
Standard templates available for:
- Initial notification
- Escalation notice
- Action plan request
- Warning letter
- Closure notification
            """,
            "keywords": ["escalation", "site issues", "procedures", "levels", "remediation"],
            "related_sections": ["SI-001", "MO-001", "PA-002"]
        },
        
        # Section 7: Essential Documents
        {
            "section_id": "ES-001",
            "category": "essential_documents",
            "title": "Trial Master File Requirements",
            "content": """
TRIAL MASTER FILE (TMF) REQUIREMENTS

TMF DEFINITION:
The Trial Master File contains essential documents that individually and collectively permit evaluation of trial conduct and data quality.

TMF STRUCTURE (ICH E6 Section 8):

1. PRE-STUDY DOCUMENTS:
- Investigator's Brochure
- Protocol and amendments
- Informed consent forms
- IRB/IEC approvals
- Regulatory submissions
- Insurance documentation
- Investigator agreements
- Financial disclosures

2. DURING TRIAL DOCUMENTS:
- Monitoring visit reports
- Communications (sponsor-site)
- Updated IB versions
- Protocol amendments
- Consent form revisions
- SAE reports
- Protocol deviation reports
- Subject enrollment logs

3. POST-TRIAL DOCUMENTS:
- Study closure notification
- Final monitoring report
- Drug accountability records
- Final IRB/IEC notification
- Clinical study report

TMF QUALITY STANDARDS:
- Complete: All required documents present
- Accurate: Documents reflect actual events
- Contemporaneous: Created at time of activity
- Legible: Readable and clear
- Attributable: Author/date identifiable

TMF INSPECTION READINESS:
Required state:
- All documents filed
- Index current
- Cross-references complete
- Filing consistent
- Archive-ready

Common deficiencies:
- Missing documents
- Unsigned documents
- Misfiled documents
- Outdated versions
- Incomplete filing

eTMF CONSIDERATIONS:
- Validated system required
- Audit trail maintained
- Access controls in place
- Backup procedures documented
- 21 CFR Part 11 compliance

TMF RETENTION:
- Per ICH: 2 years after last marketing approval
- Per local regulations: May vary by country
- Longer retention may be required
            """,
            "keywords": ["TMF", "trial master file", "essential documents", "filing", "regulatory"],
            "related_sections": ["ES-002", "MO-002", "AU-001"]
        },
        
        {
            "section_id": "ES-002",
            "category": "essential_documents",
            "title": "Document Retention Requirements",
            "content": """
DOCUMENT RETENTION REQUIREMENTS

REGULATORY REQUIREMENTS:

ICH E6 (R2):
- Investigator: 2 years after last marketing approval or 2 years after formal discontinuation
- Sponsor: Same as investigator requirements

FDA (21 CFR 312.62):
- 2 years following marketing application approval
- If no application filed: 2 years after investigation discontinued

EMA:
- 15 years after study completion (clinical trial regulation)
- Previous directive: 15 years minimum

RETENTION CATEGORIES:

Essential Documents:
- Protocol and amendments
- Informed consents (signed)
- IRB/IEC documentation
- Regulatory submissions
- AE/SAE reports
- CRFs and source data
- Monitoring reports
- Drug accountability

Supporting Documents:
- Correspondence
- Meeting minutes
- Training records
- CVs and delegation logs
- Lab certifications

RETENTION BEST PRACTICES:
1. Identify applicable requirements
2. Apply longest retention period
3. Document retention decisions
4. Implement secure storage
5. Plan for archive transfer
6. Establish destruction procedures

STORAGE REQUIREMENTS:
- Secure location
- Access controlled
- Environmental controls
- Fire/flood protection
- Regular inventory checks

ELECTRONIC RECORDS:
- System validated
- Audit trail maintained
- Backup procedures in place
- Migration plan documented
- Readable for retention period

DESTRUCTION PROCEDURES:
- Sponsor approval required
- Documentation of destruction
- Witness verification
- Secure destruction method
- Destruction certificate
            """,
            "keywords": ["retention", "archiving", "documents", "regulatory requirements", "storage"],
            "related_sections": ["ES-001", "AU-001", "RE-001"]
        },
        
        # Section 8: Cascade Analysis
        {
            "section_id": "CA-001",
            "category": "cascade_analysis",
            "title": "Cascade Intelligence Methodology",
            "content": """
CASCADE INTELLIGENCE METHODOLOGY

CONCEPT:
Cascade analysis identifies dependencies between data quality issues, enabling prioritized resolution for maximum impact.

DEPENDENCY RELATIONSHIPS:
Issues often block resolution of downstream issues:

Missing Visits → Missing Pages → Open Queries → SDV Pending → Signatures

Example cascade:
1. Missing visit creates missing pages
2. Missing pages generate queries
3. Queries block SDV completion
4. SDV blocks signature
5. Signature blocks DB lock

UNLOCK SCORE CALCULATION:
PageRank-based algorithm assigns scores:
- Higher score = More downstream impact
- Resolving high-score issues unlocks more progress

Unlock scores (typical):
- Missing Visits: 100.0 (highest impact)
- Missing Pages: 100.0
- SAE-DM Pending: 73.5
- Open Queries: 46.5
- SAE-Safety: 39.7
- SDV Pending: 37.2
- Unsigned CRFs: 31.8

CASCADE GRAPH:
Visual representation showing:
- Issue nodes
- Dependency edges
- Impact weights
- Critical path

CASCADE NARRATIVES:
Natural language explanations:
"Fix Missing Visits (1) at Site_177
→ Unlocks Missing Pages → Unlocks Queries → Unlocks SDV
→ Net impact: 8 downstream issues resolved"

PRIORITIZATION STRATEGY:
1. Identify issues with highest unlock scores
2. Group by responsible party
3. Calculate effort vs. impact ratio
4. Prioritize high-impact, low-effort items
5. Execute in dependency order

CASCADE CLUSTERS:
Group patients by issue combination:
- Only SDV Pending (simple fix)
- Missing + Queries (cascade)
- SAE + SDV (safety + monitoring)
- Complex (4+ issues)

BEST PRACTICES:
1. Always analyze cascades before prioritizing
2. Don't fix downstream issues first
3. Consider responsible parties
4. Track cascade resolution
5. Update priorities as issues resolve
            """,
            "keywords": ["cascade", "dependencies", "unlock score", "prioritization", "impact analysis"],
            "related_sections": ["CA-002", "DQ-001", "CL-002"]
        },
        
        {
            "section_id": "CA-002",
            "category": "cascade_analysis",
            "title": "Critical Path to Database Lock",
            "content": """
CRITICAL PATH TO DATABASE LOCK

CRITICAL PATH DEFINITION:
The sequence of dependent activities that determines the minimum time required to reach database lock.

IDENTIFYING CRITICAL PATH:
1. Map all blocking issues
2. Identify dependencies
3. Calculate resolution time for each
4. Find longest dependent chain
5. This chain is the critical path

CRITICAL PATH COMPONENTS:

Typical critical path:
Missing Data → Queries → SDV → Signatures → Lock

Time estimates:
- Missing Data: 2-5 days (site response)
- Query Resolution: 3-7 days (back and forth)
- SDV Completion: 1-3 days (CRA visit)
- Signatures: 1-2 days (PI availability)
- Lock Execution: 1 day

CRITICAL PATH OPTIMIZATION:

Parallel Processing:
- Work on independent paths simultaneously
- Assign different resources to different paths
- Reduce overall timeline

Resource Prioritization:
- Focus resources on critical path items
- Non-critical items can wait
- Avoid context switching

Bottleneck Resolution:
- Identify slowest step
- Add resources if possible
- Remove dependencies if possible

TIMELINE PROJECTION:
Use critical path to project lock date:
- Current state analysis
- Issue resolution estimates
- Resource availability
- Buffer for unexpected issues

DB LOCK PROJECTION EXAMPLE:
"Current: 68% DB Lock Ready
Critical Path: 5 SAE reconciliation issues
If resolved by Friday: 89% ready
Projected lock date: March 22 (CI: ±5 days)"

MONITORING CRITICAL PATH:
- Daily tracking of critical items
- Escalation if delays occur
- Re-assessment after major changes
- Communication to stakeholders

SCENARIO ANALYSIS:
What-if scenarios:
- "What if we add CRA resource?"
- "What if PI is unavailable next week?"
- "What if we expedite SAE review?"
            """,
            "keywords": ["critical path", "timeline", "optimization", "database lock", "projection"],
            "related_sections": ["CA-001", "DB-001", "SI-001"]
        },
        
        # Section 9: Pattern Recognition
        {
            "section_id": "PA-001",
            "category": "patterns",
            "title": "Known Issue Patterns",
            "content": """
KNOWN ISSUE PATTERNS IN CLINICAL TRIALS

Pattern recognition enables early intervention based on validated patterns observed across studies.

VALIDATED PATTERNS:

1. COORDINATOR OVERLOAD (PAT-RC-001)
Detection: >30 subjects per coordinator
Impact: Quality decline, delayed data entry
Indicators:
- Increased query rate
- Longer CRF completion times
- Missing data increase
Resolution: Add coordinator support

2. PI ABSENCE CASCADE (PAT-TL-001)
Detection: No signatures for 7+ days
Impact: Signature backlog, lock delays
Indicators:
- Overdue signature count
- Broken signature rate
- Site inactivity
Resolution: Batch signature session, delegate

3. NEW SITE RAMP PATTERN
Detection: First 60 days after activation
Impact: Higher query rate, protocol deviations
Indicators:
- Query rate 2x average
- Training gaps evident
- Documentation issues
Resolution: Enhanced support, re-training

4. END-OF-MONTH RUSH
Detection: Last week of month spike
Impact: Data quality dip
Indicators:
- Bulk data entry
- Increased errors
- Resource strain
Resolution: Stagger deadlines, daily entry emphasis

5. QUERY PING-PONG
Detection: Same query re-opened 3+ times
Impact: Resolution delays
Indicators:
- High re-open rate
- Incomplete responses
- Frustration
Resolution: Phone resolution, clarification

6. SDV BACKLOG
Detection: >100 CRFs pending SDV
Impact: Lock timeline risk
Indicators:
- SDV rate declining
- Visit gaps
- CRA resource constraints
Resolution: Additional monitoring visits

PATTERN CONFIDENCE:
- Validated: Observed in 3+ studies
- Emerging: Observed in 1-2 studies
- Hypothesized: Theoretical pattern

PATTERN RESPONSE:
1. Detection: Pattern match identified
2. Verification: Confirm pattern applies
3. Alert: Notify responsible parties
4. Action: Implement resolution
5. Monitor: Track effectiveness
            """,
            "keywords": ["patterns", "recognition", "detection", "coordinator overload", "PI absence"],
            "related_sections": ["PA-002", "AN-001", "SI-001"]
        },
        
        {
            "section_id": "PA-002",
            "category": "patterns",
            "title": "Anomaly Detection and Response",
            "content": """
ANOMALY DETECTION AND RESPONSE

ANOMALY DEFINITION:
Data patterns that deviate significantly from expected behavior, potentially indicating data quality issues, fraud, or unusual circumstances.

ANOMALY DETECTION METHODS:

Statistical Methods:
- Z-score analysis (>2σ from mean)
- Interquartile range (IQR)
- Percentile thresholds (P95, P99)

Machine Learning:
- Isolation Forest
- Local Outlier Factor (LOF)
- Autoencoder reconstruction error

Pattern-Based:
- Unusual data entry times
- Digit preference
- Value clustering

ANOMALY CATEGORIES:

Patient-Level:
- Unusual data patterns for individual subject
- Inconsistent data across visits
- Extreme values

Site-Level:
- Different patterns from peer sites
- Unusual enrollment patterns
- Homogeneous data

Study-Level:
- Regional differences
- Temporal trends
- Emerging safety signals

ANOMALY SEVERITY:

Critical (P99+): 1% most extreme
- Immediate investigation required
- Potential data integrity issue
- Possible fraud indicator

High (P95-P99): 4% next most extreme
- Investigation within 48 hours
- Enhanced monitoring needed
- Root cause analysis

Medium (P90-P95): 5% next
- Review at next visit
- Document explanation
- Monitor for trends

Low (<P90): Within normal variation
- No action required
- Monitor if recurring

INVESTIGATION PROCESS:
1. Detection: Anomaly flagged by system
2. Verification: Confirm anomaly is real
3. Investigation: Root cause analysis
4. Documentation: Record findings
5. Resolution: Address if valid issue
6. Monitoring: Track for recurrence

FALSE POSITIVE MANAGEMENT:
- Document legitimate explanations
- Update detection rules
- Maintain institutional knowledge
- Review false positive rate
            """,
            "keywords": ["anomaly", "detection", "outlier", "investigation", "fraud", "data integrity"],
            "related_sections": ["PA-001", "DQ-001", "SA-002"]
        },
        
        # Section 10: Regulatory Compliance
        {
            "section_id": "RE-001",
            "category": "regulatory",
            "title": "21 CFR Part 11 Compliance",
            "content": """
21 CFR PART 11 COMPLIANCE

OVERVIEW:
21 CFR Part 11 establishes FDA requirements for electronic records and electronic signatures to be considered trustworthy, reliable, and equivalent to paper records.

KEY REQUIREMENTS:

1. VALIDATION (§11.10(a)):
- Systems must be validated
- Intended use established
- Validation documented

2. AUDIT TRAILS (§11.10(e)):
- Computer-generated
- Time-stamped
- Independent of operator
- Cannot be modified

3. ACCESS CONTROLS (§11.10(d)):
- Limiting system access
- Authority levels defined
- User-specific accounts
- Automatic logoff

4. ELECTRONIC SIGNATURES (§11.100):
- Unique to individual
- Not reused or reassigned
- Two components (ID + password)
- Linked to electronic record

5. SIGNATURE MANIFESTATIONS (§11.50):
- Name of signer
- Date and time
- Meaning (approval, review, etc.)

6. SIGNATURE LINKING (§11.70):
- Signatures linked to records
- Cannot be copied/transferred
- Invalidation detectable

TRIALPULSE COMPLIANCE:

Audit Trail:
- All data changes logged
- User, timestamp, old/new values
- Immutable log (append-only)
- Exportable for inspection

Access Control:
- Role-based access
- User authentication
- Session management
- Privilege verification

Data Integrity:
- Input validation
- Checksums
- Backup procedures
- Recovery testing

COMPLIANCE DOCUMENTATION:
- System validation report
- User access procedures
- Audit trail procedures
- Backup/recovery procedures
- Training records

INSPECTION READINESS:
- Audit trail exportable
- User access logs available
- Validation documentation current
- SOPs up to date
            """,
            "keywords": ["21 CFR Part 11", "electronic records", "audit trail", "compliance", "FDA"],
            "related_sections": ["RE-002", "ES-001", "AU-001"]
        },
        
        {
            "section_id": "RE-002",
            "category": "regulatory",
            "title": "GDPR and Privacy Considerations",
            "content": """
GDPR AND PRIVACY CONSIDERATIONS IN CLINICAL TRIALS

GDPR OVERVIEW:
The General Data Protection Regulation applies to processing of personal data of EU subjects, including clinical trial participants.

LAWFUL BASIS FOR PROCESSING:
Clinical trials typically rely on:
- Consent (informed consent for trial participation)
- Legal obligation (regulatory requirements)
- Scientific research exemption (with safeguards)

KEY GDPR PRINCIPLES:

1. Lawfulness, Fairness, Transparency
- Clear communication about data use
- Legitimate basis for processing
- Accessible privacy notices

2. Purpose Limitation
- Data collected for specified purposes
- No incompatible secondary use
- Research exemption may apply

3. Data Minimization
- Only necessary data collected
- Avoid excessive data collection
- Regular review of data needs

4. Accuracy
- Data kept up to date
- Correction mechanisms in place
- Verification procedures

5. Storage Limitation
- Defined retention periods
- Deletion when no longer needed
- Research exemption considerations

6. Security
- Appropriate technical measures
- Organizational safeguards
- Breach notification procedures

SUBJECT RIGHTS:
- Right to access
- Right to rectification
- Right to erasure (limited in trials)
- Right to data portability
- Right to object

PSEUDONYMIZATION:
- Subject ID codes used
- Linking file secured
- Key held by investigator
- Re-identification limited

DATA TRANSFERS:
- Adequacy decisions
- Standard contractual clauses
- Binding corporate rules
- Explicit consent

TRIALPULSE APPROACH:
- Subject codes only (no direct identifiers)
- Role-based access
- Audit trails
- Data minimization
- Secure transmission
            """,
            "keywords": ["GDPR", "privacy", "data protection", "consent", "pseudonymization"],
            "related_sections": ["RE-001", "ES-002", "AU-001"]
        },
        
        # Section 11: Audit and Inspection
        {
            "section_id": "AU-001",
            "category": "audit",
            "title": "Audit Trail Requirements",
            "content": """
AUDIT TRAIL REQUIREMENTS

DEFINITION:
An audit trail is a secure, computer-generated, time-stamped record that allows reconstruction of events relating to creation, modification, or deletion of electronic records.

REGULATORY REQUIREMENTS:

FDA (21 CFR 11.10(e)):
- Computer-generated, time-stamped
- Independent of system operators
- Available for regulatory review
- Record any changes to data

EMA (Annex 11):
- All GxP relevant changes recorded
- Previous values available
- Reason for change documented
- User and timestamp recorded

AUDIT TRAIL COMPONENTS:

What to capture:
- User ID
- Date and time
- Action performed
- Old value
- New value
- Reason for change (where applicable)

Actions to log:
- Create
- Read (for sensitive data)
- Update
- Delete
- Sign
- Approve
- Login/logout

AUDIT TRAIL BEST PRACTICES:

1. Immutability
- Append-only log
- Cannot modify entries
- Tamper-evident

2. Completeness
- All changes captured
- No gaps in record
- Includes system events

3. Accessibility
- Easily exportable
- Human-readable format
- Available for inspection

4. Review
- Regular audit trail review
- Documented review process
- Anomaly investigation

TRIALPULSE AUDIT TRAIL:

Captures:
- All data changes
- User actions
- Agent recommendations
- Human decisions
- Override reasons

Format:
- Timestamp (ISO 8601)
- User/Agent ID
- Action type
- Entity affected
- Before/after values
- Reasoning (for AI actions)

Export:
- JSON format
- CSV format
- Regulatory format
- Date range filtering
            """,
            "keywords": ["audit trail", "logging", "traceability", "regulatory", "changes"],
            "related_sections": ["AU-002", "RE-001", "ES-001"]
        },
        
        {
            "section_id": "AU-002",
            "category": "audit",
            "title": "Inspection Preparation Guide",
            "content": """
INSPECTION PREPARATION GUIDE

INSPECTION TYPES:

FDA Inspection:
- Pre-approval (pre-NDA/BLA)
- Routine surveillance
- For-cause investigation
- BIMO (Bioresearch Monitoring)

EMA Inspection:
- GCP inspection
- Pharmacovigilance inspection
- GMP inspection

Sponsor Audit:
- Internal quality audits
- CRO oversight audits
- Vendor audits

INSPECTION PREPARATION CHECKLIST:

DOCUMENTATION:
☐ TMF complete and organized
☐ All documents signed/dated
☐ Version control current
☐ Cross-references accurate
☐ Index up to date

SITE READINESS:
☐ All staff available
☐ Delegation log current
☐ Training records complete
☐ Source documents accessible
☐ IP accountability complete

DATA SYSTEMS:
☐ Audit trails available
☐ User access logs ready
☐ Validation documentation current
☐ Data exports prepared

KEY DOCUMENTS TO PREPARE:
1. Protocol and amendments
2. IRB/IEC approvals
3. Informed consent forms
4. Investigator CVs and logs
5. Monitoring reports
6. SAE reports
7. Protocol deviations
8. Drug accountability

INSPECTION DAY PROCEDURES:
1. Designate inspection point person
2. Prepare inspection room
3. Brief staff on process
4. Document requests promptly
5. Provide requested documents
6. Note inspector questions
7. Prepare daily summary

POST-INSPECTION:
- Address observations promptly
- Develop CAPA if needed
- Document corrective actions
- Track to completion
- Prepare response letter

COMMON FINDINGS:
- Informed consent issues
- Protocol deviations not reported
- Source document discrepancies
- AE/SAE reporting delays
- Inadequate oversight
- Missing essential documents
            """,
            "keywords": ["inspection", "preparation", "FDA", "audit", "readiness", "CAPA"],
            "related_sections": ["AU-001", "ES-001", "RE-001"]
        }
    ]
}


def get_protocol_knowledge() -> dict:
    """Return the complete protocol knowledge base."""
    return PROTOCOL_KNOWLEDGE_BASE


def get_protocol_section(section_id: str) -> dict:
    """Get a specific section by ID."""
    for section in PROTOCOL_KNOWLEDGE_BASE["sections"]:
        if section["section_id"] == section_id:
            return section
    return None


def get_sections_by_category(category: str) -> list:
    """Get all sections in a category."""
    return [s for s in PROTOCOL_KNOWLEDGE_BASE["sections"] if s["category"] == category]


def get_all_categories() -> list:
    """Get list of all categories."""
    categories = set()
    for section in PROTOCOL_KNOWLEDGE_BASE["sections"]:
        categories.add(section["category"])
    return sorted(list(categories))


def search_protocol_knowledge(query: str) -> list:
    """Search protocol knowledge base."""
    query_lower = query.lower()
    results = []
    
    for section in PROTOCOL_KNOWLEDGE_BASE["sections"]:
        score = 0
        
        # Title match (highest weight)
        if query_lower in section["title"].lower():
            score += 10
        
        # Keyword match (high weight)
        for keyword in section.get("keywords", []):
            if query_lower in keyword.lower():
                score += 5
        
        # Content match (lower weight)
        if query_lower in section["content"].lower():
            score += 1
        
        if score > 0:
            results.append({
                "section_id": section["section_id"],
                "category": section["category"],
                "title": section["title"],
                "relevance_score": score,
                "keywords": section.get("keywords", [])
            })
    
    # Sort by relevance score
    results.sort(key=lambda x: x["relevance_score"], reverse=True)
    return results